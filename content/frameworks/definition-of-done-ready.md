---
id: "definition-of-done-ready"
title: "üéØ Definition of Done (DoD) & Definition of Ready (DoR)"
category: "frameworks"
tags: ["scrum", "artefacts", "qualit√©", "transparence", "crit√®res", "user-story", "backlog"]
description: "Les deux piliers de la qualit√© en Agile : comment d√©finir clairement quand une story est pr√™te √† √™tre d√©marr√©e (DoR) et quand elle est termin√©e (DoD)."
---

# **üéØ Definition of Done (DoD) & Definition of Ready (DoR)**
*Parce qu'en Agile, "presque fini" = "pas fini", et "√† peu pr√®s clair" = "flou artistique."*

**Tags** : `#scrum` `#artefacts` `#qualit√©` `#transparence` `#crit√®res` `#user-story` `#backlog`

> *"Une DoD floue, c‚Äôest comme un GPS sans destination : tu avances, mais tu ne sais pas quand tu es arriv√©. Et une DoR inexistante, c‚Äôest comme partir en voyage sans valise : tu vas perdre du temps √† faire demi-tour."*
> ‚Äî **Coach Sticko**

---

## **üí° Pitch**
**Probl√®me** :
- **40%** des √©quipes Agile livrent des incr√©ments avec des **bugs critiques** car la DoD n‚Äôest pas respect√©e (*State of Agile Report*).
- **30%** des stories en sprint sont **mal estim√©es** car la DoR n‚Äô√©tait pas claire (*Scrum Alliance*).
- R√©sultat : **rework**, frustration, et une v√©locit√© qui ressemble √† des montagnes russes.

**Solutions** :
1. **DoR** = **"Checklist de d√©part"** : *"Cette story est-elle assez m√ªre pour √™tre d√©marr√©e ?"*
2. **DoD** = **"Ligne d‚Äôarriv√©e"** : *"√Ä quel moment pouvons-nous dire que c‚Äôest termin√©, sans culpabilit√© ?"*

*Exemple* :
- **DoR** pour *"En tant qu‚Äôutilisateur, je veux r√©initialiser mon mot de passe"* :
  - [ ] Le design des √©crans est valid√©.
  - [ ] Les r√®gles m√©tiers sont document√©es (ex: "Lien valide 24h").
  - [ ] Les d√©pendances techniques sont identifi√©es (ex: API d‚Äôenvoi d‚Äôemail).
- **DoD** :
  - [ ] Code revu par un pair.
  - [ ] Tests unitaires et d‚Äôint√©gration pass√©s.
  - [ ] Documentation utilisateur mise √† jour.

---
## **üìñ D√©finition & Origines**
### **Definition of Ready (DoR)**
**Quoi** : Liste de crit√®res qu‚Äôune **user story** doit satisfaire pour √™tre **√©ligible** √† un sprint.
**Pourquoi** :
- √âviter les stories **"trop grosses"** ou **"trop floues"**.
- Garantir que l‚Äô√©quipe a **toutes les infos** pour estimer et d√©marrer le travail.
- R√©duire les **blocages en cours de sprint**.

**Origine** :
Popularis√©e par **Roman Pichler** et **Mike Cohn** pour r√©pondre au probl√®me des backlogs mal pr√©par√©s.
- **Roman Pichler** (Product Owner expert, auteur de "Agile Product Management")
- **Mike Cohn** (fondateur de Mountain Goat Software, r√©f√©rence en User Stories) ont formalis√© ces concepts pour structurer les backlogs produit.


---
### **Definition of Done (DoD)**
**Quoi** : Liste de crit√®res qu‚Äôun **incr√©ment** (story, t√¢che) doit satisfaire pour √™tre consid√©r√© comme **termin√©**.
**Pourquoi** :
- **Transparence** : tout le monde sait ce que "fini" signifie.
- **Qualit√©** : √©viter les livraisons **"√† moiti√© cuites"**.
- **Pr√©visibilit√©** : la v√©locit√© devient fiable.

**Origine** :
Issue de **Scrum** (Ken Schwaber, 1995), inspir√©e des pratiques de **Total Quality Management (TQM)**.

---
## **üîç DoR vs DoD : Comparatif**
| Crit√®re               | **üîµ Definition of Ready (DoR)**                      | **üü¢ Definition of Done (DoD)**                          |
|-----------------------|-------------------------------------------------------|-------------------------------------------------------|
| **Quand ?**           | **Avant** le sprint planning.                          | **√Ä la fin** du sprint (ou de la story).               |
| **Objectif**          | S‚Äôassurer que la story est **compr√©hensible et faisable**. | Garantir que le travail est **complet et de qualit√©**. |
| **Port√©e**            | **1 story** √† la fois.                                | **Tout l‚Äôincr√©ment** (toutes les stories du sprint).   |
| **Responsable**       | **Product Owner** (avec l‚Äô√©quipe).                     | **√âquipe de d√©veloppement** (avec le PO).              |
| **Exemple de crit√®re** | "Les maquettes sont valid√©es."                        | "Les tests de non-r√©gression sont pass√©s."             |
| **Cons√©quence si ignor√©** | Stories **sous-estim√©es** ou **bloqu√©es**.          | **Rework**, bugs en production, dette technique.       |

---
## **üìã Exemples Concrets**
### **1. Definition of Ready (DoR)**
**Template g√©n√©rique** (√† adapter) :
```markdown
‚úÖ **Clart√©** :
- [ ] La story a une **description claire** (format "En tant que... je veux... afin de...").
- [ ] Les **crit√®res d‚Äôacceptation** sont d√©finis et testables.
- [ ] Les **d√©pendances** (techniques, m√©tiers) sont identifi√©es.

‚úÖ **Taille** :
- [ ] La story est **estimable** (pas de "?" en planning poker).
- [ ] La story tient dans **un sprint** (ou est d√©coup√©e en sous-t√¢ches).

‚úÖ **Contexte** :
- [ ] Les **r√®gles m√©tiers** sont document√©es (ex: "Le mot de passe doit faire 8 caract√®res min").
- [ ] Les **maquettes/UI** sont disponibles (si applicable).
- [ ] Les **donn√©es test** sont pr√™tes (ex: jeux de donn√©es pour les tests).
```

**Exemple pour une story e-commerce** :
*"En tant qu‚Äôutilisateur, je veux payer avec PayPal afin d‚Äôavoir plus d‚Äôoptions de paiement."*
- [x] Les APIs PayPal sont document√©es et accessibles.
- [x] Le design des √©crans de paiement est valid√©.
- [x] Les frais de transaction PayPal sont clarifi√©s avec la compta.
- [x] La story est estim√©e √† **5 story points** (consensus en planning poker).

---
### **2. Definition of Done (DoD)**
**Template g√©n√©rique** (niveaux progressifs) :
```markdown
üîπ **Niveau 1 (Minimum)** :
- [ ] Le code est **commit√©** et **pouss√©** sur la branche principale.
- [ ] Le code est **revu par un pair** (pull request merg√©e).
- [ ] Les **tests unitaires** passent.

üîπ **Niveau 2 (Standard)** :
- [ ] Les **tests d‚Äôint√©gration** passent.
- [ ] La **documentation technique** est mise √† jour (README, commentaires).
- [ ] La **story est d√©ploy√©e en staging** et test√©e manuellement.

üîπ **Niveau 3 (Excellence)** :
- [ ] Les **tests de non-r√©gression** passent.
- [ ] La **documentation utilisateur** est mise √† jour (wiki, help center).
- [ ] Les **m√©triques de performance** sont dans les limites (ex: temps de r√©ponse < 2s).
- [ ] La story est **d√©ploy√©e en production** et monitor√©e.
```

**Exemple pour une √©quipe DevOps** :
- [x] Code revu et merg√©.
- [x] Pipeline CI/CD passe (build + tests + d√©ploiement auto).
- [x] Feature flag activ√©e en production.
- [x] M√©triques (latence, erreurs) surveill√©es 24h apr√®s d√©ploiement.

---
## **üõ†Ô∏è Comment Construire sa DoD/DoR ?**
### **Atelier Collaboratif (1h)**
**Participants** : √âquipe de dev + PO + Scrum Master.
**Mat√©riel** : Tableau blanc, post-its, timer.

#### **√âtapes pour la DoD** :
1. **Brainstorming** (15 min) :
   - *"Qu‚Äôest-ce que 'fini' signifie pour nous ?"* (1 crit√®re = 1 post-it).
2. **Regroupement** (10 min) :
   - Th√®mes communs (ex: "Tests", "Documentation", "D√©ploiement").
3. **Priorisation** (10 min) :
   - *"Quels sont les 3 crit√®res **non-n√©gociables** ?"* (vote dot).
4. **Validation** (5 min) :
   - *"Est-ce que cette DoD est **r√©aliste** et **mesurable** ?"*
5. **Documentation** (10 min) :
   - √âcrire la DoD dans le **Confluence de l‚Äô√©quipe** ou sur un **tableau Miro partag√©**.

#### **√âtapes pour la DoR** :
1. **Analyse des blocages pass√©s** (10 min) :
   - *"Quelles stories ont √©t√© bloqu√©es ou mal estim√©es dans le dernier sprint ? Pourquoi ?"*
2. **Crit√®res minimaux** (15 min) :
   - *"Quelles infos devons-nous avoir **avant** de d√©marrer une story ?"*
3. **Validation avec le PO** (10 min) :
   - *"Est-ce que ces crit√®res sont **r√©alistes** pour le PO ?"*
4. **Int√©gration au workflow** (5 min) :
   - Ajouter la DoR comme **colonne dans Jira** ("Ready for Refinement" ‚Üí "Ready for Sprint").

---
## **‚ö†Ô∏è Pi√®ges √† √âviter**
| Pi√®ge                          | Cons√©quence                                  | Solution                                  |
|--------------------------------|---------------------------------------------|-------------------------------------------|
| **DoD trop vague**             | "Fini" signifie quelque chose de diff√©rent pour chacun. | **Exemples concrets** (ex: "Tests = 100% coverage"). |
| **DoD trop stricte**          | L‚Äô√©quipe passe plus de temps √† cocher des cases qu‚Äô√† livrer. | **Niveaux progressifs** (ex: Niveau 1 pour les MVP). |
| **DoR ignor√©e**               | Stories "pourries" en sprint ‚Üí blocages.    | **Refinement obligatoire** avant le planning. |
| **DoD/DoR impos√©es**          | L‚Äô√©quipe ne s‚Äôapproprie pas les crit√®res.  | **Co-construction en atelier**.           |
| **DoD diff√©rente par √©quipe**  | Incoh√©rences dans la qualit√©.              | **Alignement entre √©quipes** (guilde qualit√©). |

---
## **üìä Avantages Mesurables**
| B√©n√©fice               | M√©trique d‚ÄôImpact                          | Exemple                                  |
|------------------------|-------------------------------------------|------------------------------------------|
| **Moins de rework**    | ‚Üì **30% de bugs en production**.          | De 15 bugs/sprint √† 10 bugs/sprint.      |
| **Meilleure v√©locit√©** | ‚Üë **Stabilit√© de la v√©locit√©** (¬±10%).  | V√©locit√© passe de [30, 45, 20] √† [40, 42, 45]. |
| **Transparence**       | ‚Üì **20% de malentendus** en sprint review. | Plus de "Je pensais que c‚Äô√©tait fini !". |
| **Autonomie**          | ‚Üë **D√©cisions prises sans le PO**.        | √âquipe d√©cide seule si une story est "ready". |

---
## **üéØ DoD/DoR dans Diff√©rents Contextes**
### **1. √âquipe Produit (Scrum/Kanban)**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Maquettes Figma valid√©es.<br>- R√®gles m√©tiers document√©es (Confluence).<br>- D√©pendances techniques identifi√©es (ex: API externe). | Jira (champ "DoR Checklist"), Miro. |
| **DoD**        | - Tests E2E pass√©s (Cypress).<br>- Feature flag activ√©e.<br>- M√©triques de performance (New Relic) dans les limites. | Pipeline CI/CD (Jenkins, GitLab CI). |

---
### **2. √âquipe Data Science**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Jeu de donn√©es nettoy√© et disponible (S3).<br>- Hypoth√®se √† valider clairement formul√©e.<br>- Environnement de calcul r√©serv√© (AWS). | Jupyter Notebook + Dataiku. |
| **DoD**        | - Mod√®le entra√Æn√© et √©valu√© (AUC > 0.9).<br>- Code versionn√© (MLflow).<br>- Dashboard de monitoring (Grafana) d√©ploy√©. | MLflow, TensorBoard. |

---
### **3. √âquipe DevOps/Infrastructure**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Sch√©ma d‚Äôarchitecture valid√© (Lucidchart).<br>- Acc√®s aux environnements (AWS, Kubernetes).<br>- Backlog des risques identifi√©s. | Terraform, ArgoCD. |
| **DoD**        | - Infrastructure as Code (IaC) versionn√©e.<br>- Tests de s√©curit√© (OWASP ZAP) pass√©s.<br>- Runbook mis √† jour. | Terraform Cloud, SonarQube. |

---
### **4. √âquipe RH/Recrutement**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Fiche de poste valid√©e par le manager.<br>- Budget et niveau de salaire approuv√©s (DRH).<br>- Canaux de diffusion identifi√©s (LinkedIn, JobBoard). | Workday, BambooHR. |
| **DoD**        | - Candidat s√©lectionn√© et contrat sign√©.<br>- Onboarding planifi√© (buddy, mat√©riel).<br>- Feedback collect√© aupr√®s du manager recruteur. | ATS (Applicant Tracking System). |

---
### **5. √âquipe Militaire/Op√©rationnelle**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Ordre de mission sign√© par la hi√©rarchie.<br>- Mat√©riel et √©quipements v√©rifi√©s (check-list).<br>- Briefing s√©curit√© effectu√© (ROE, menaces). | SICS (Syst√®me d'Information de Commandement). |
| **DoD**        | - Mission accomplie selon les objectifs.<br>- Rapport de mission (RETEX) r√©dig√©.<br>- Mat√©riel rendu et inventori√©.<br>- D√©briefing s√©curit√© effectu√©. | Logiciel de gestion op√©rationnelle. |

---
### **6. Association Sportive/√âv√©nementiel**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Budget √©v√©nement valid√© par le bureau.<br>- Lieu et date r√©serv√©s (contrat sign√©).<br>- √âquipe de b√©n√©voles constitu√©e (min 5 personnes). | HelloAsso, Eventbrite. |
| **DoD**        | - √âv√©nement r√©alis√© avec 90% de participants pr√©sents.<br>- Bilan financier √©tabli (recettes/d√©penses).<br>- Feedback participants collect√© (satisfaction > 4/5).<br>- Photos/vid√©os partag√©es sur r√©seaux sociaux. | Google Forms, Canva. |

### **7. √âquipe M√©dicale/Hospitali√®re**
| Artefact       | Crit√®res Sp√©cifiques                              | Outils Associ√©s                          |
|----------------|---------------------------------------------------|------------------------------------------|
| **DoR**        | - Dossier patient complet et accessible (DPI).<br>- Protocole de soins valid√© par le m√©decin r√©f√©rent.<br>- Mat√©riel m√©dical disponible et st√©rilis√©.<br>- √âquipe soignante brief√©e (allergies, ant√©c√©dents). | DPI (Dossier Patient Informatis√©), PMSI. |
| **DoD**        | - Soins prodigu√©s selon le protocole.<br>- Observations m√©dicales consign√©es dans le dossier.<br>- Patient stabilis√© (constantes dans les normes).<br>- Transmission effectu√©e √† l'√©quipe suivante.<br>- Mat√©riel nettoy√© et restock√©. | Logiciel de gestion hospitali√®re (Crossway, McKesson). |

---
## **üìå Checklist pour Impl√©menter DoD/DoR**
### **Pour les √âquipes**
- [ ] **Co-construire** la DoD/DoR en atelier (pas impos√©e par le PO ou le SM).
- [ ] **Afficher la DoD/DoR** dans l‚Äôespace de travail (Miro, Confluence, mur physique).
- [ ] **V√©rifier la DoR** avant chaque **refinement** et **planning**.
- [ ] **Valider la DoD** √† chaque **sprint review** (avec d√©monstration).
- [ ] **R√©viser la DoD/DoR** tous les **3 sprints** (am√©lioration continue).

### **Pour les Scrum Masters**
- [ ] **Former l‚Äô√©quipe** sur l‚Äôimportance de la DoD/DoR (ex: atelier "Pourquoi on en a besoin ?").
- [ ] **Bloquer les stories** qui ne respectent pas la DoR (m√™me si le PO insiste).
- [ ] **Mesurer l‚Äôimpact** (ex: "Depuis qu‚Äôon applique la DoD, on a 20% de bugs en moins").
- [ ] **Escalader** si des d√©pendances externes bloquent la DoR (ex: design manquant).

### **Pour les Product Owners**
- [ ] **Pr√©parer les stories** avec la DoR **avant le refinement**.
- [ ] **Accepter que des stories soient rejet√©es** si la DoR n‚Äôest pas respect√©e.
- [ ] **Prioriser la dette technique** si elle emp√™che de respecter la DoD.

---
> *"Une DoD sans DoR, c‚Äôest comme construire une maison sans fondations. Une DoR sans DoD, c‚Äôest comme avoir un beau plan‚Ä¶ mais une maison jamais finie. Les deux sont les **jumeaux indissociables** de la qualit√© Agile."*
> ‚Äî **Coach Sticko** üèóÔ∏è